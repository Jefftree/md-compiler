# Foundation of Sequential Programs

A sequential program runs its instructions one at a time.

- Machine Language (A1)
- Assembler
- Assembly Language (A2)
- Compiler (A6- A10)
- C/C++/Racket

## Data Representation


$$ 67 = 64 + 2 + 1 = 2^6 + 2^1 + 2^0 = 1000011$$

Decimal, Binary, Octal, Hexadecimal Representations

Unsigned binary: $0 - 2^{n} -1$

**Sign and magnitude**:

- Two representations of 0
- Additional and subtraction require separate hardware

**Two's complement**:

- Use congruence to represent negative numbers
- Represent negative number as $N - b$
- Positive numbers are unchanged
- Flip the bits and add one for negative numbers
- Signed binary number:  Look at first bit

**Aside**: Let $a, b$ be two positive numbers. $(a-b = a + (N - b))$ mod $N$ where $N = 2^n$

$N - b$ is easy to do because $(N - 1 - b) + 1$ and flipping bits is fast

Converting two's complement to decimal

- Treat number as unsigned number and convert to decimal
- If first bit represents positive number, done
- If first bit represents negative number, subtract $N$

### Comparisons

Signed and unsigned need separate comparisons. Static typing helps select the comparison type.

## Machine Language

**Machine Language**: Set of machine instructions. Understood by a particular machine/processor

**Machine Instruction**: Sequence of bits having exactly one meaning

### MIPS Processor

- Control Unit: Controls flow of data, timing, and executing the program
- ALU: Arithmetic Logic Unit: Math operations
- Memory: 32bit (word)
- Register: Small amount of very fast memory (32 bits each), (MAR, MDR)
- Program Counter: Special register that always holds address of the next instruction to execute
- Instruction Register: Holds current instruction (32 bits)
- 32 General purpose registers (Use \$ to represent registers)
- Register 0 always contains the value 0

Processor communicates with memory through data bus

To run a program, the loader loads the program into memory starting at address 0.

**Fetch-decode-execute algorithm**:

- Hardcoded as a circuit in the control unit
- Sets program counter to 0
- **Program counter**: Contains the address of the next instruction

```asm
loop {
    IR <-- MEM[PC]
    PC <-- PC + 4
    decode
    execute
}
```

**Note:** Explicitly need to jump out of the fetch-decode-execute cycle to exit the program

`$31` contains a special instruction that is similar to the return statement in C++.

## MIPS

Clear value of a register `$add $4 $0 $0`

Negate value of a register `$sub $4 $0 $4`

Copy value to another register `add $3 $0 $1`

Terminate program: `jr $31`

`xxd -b file.bin` shows binary values

**Example:** Add 42 and 52 and store the result in `$3`

**Solution:**

**Load immediate**: `lis $d`

`d <- MEM[PC], PC <- PC + 4`

```asm
lis $5
.word 42
lis $7
.word 52
add $3 $5 $7
jr $31
```


**Assembly Language**: Textual representation of machine language: Less tedious, less error prone, abstraction over machine language.

`cs241.binasm` converts assembly to binary

**Example**: Compute the absolute value of `$1` and store the result in `$1`

**Set Less Than**: `slt $d $s $t`

Branch on Equal: `beq $s $t i`
- If `$s == $t`, `pc = pc + i * 4`

Branch on Not Equal: `bne $s $t i`


**Solution**:

```asm
slt $2, $1, $0
beq $2, $0, 1
sub $1, $0, $1
jr $31
```

Alternate Implementation:

```asm
slt $2, $1, $0
bne $2, $0, 1
jr $31
sub $1, $0, $1
jr $31
```

**Unconditional Jump**: `beq $0 $0 5`

**Example**: Calculate $13 + 12 + 11 + \cdots + 1$ Store result in `$3`

**Solution**:

```asm
lis $2
.word 13
add $3, $0, $0
lis $1
.word -1
add $3 $3 $2
add $2 $1 $2
bne $2 $0 -3
jr $31
```

`.word loop` is the address of the instruction

**Load Word**: `lw $t i($s)`

- Loads a word from memory.
- `i` is 16 bits signed $2$'s complement'
- `$t <- MEM[$s + i]`

**Store Word:** `sw $t i($s)`

- Store a word from a register into memory
- `MEM[$s + i] = $t`

#### Writing Standard Output

**Magic address**: `0xffff000c`

If something is stored at this address, least significant byte is outputted to `stdout`

```asm
lis $1
.word 0xffff000c
lis $2
.word 67
sw $2, 0($1)
```

Outputs  ASCII value for $67$ which is `C`

**Multiplication:** `mult` and `multu`

- `mult $s, $t`
- There is no target register
- Result may be bigger than $32$ bits
- `hi:lo` register is used
- `hi` stores most significant bits and `lo` stores least significant bits

**Division:** `div` and `divu`

- `lo` is quotient `$s / $t`
- `hi` is remainder `$s % $t`

**Accessing `hi` and `low`**

- Use `mfhi` and `mflo`
- `mfhi $4` moves content of high register into register 4

**Example**:

- `$1` contains address of a 32 bit array of integers, denote this `arr`
- `$2` contains length of array
- Goal: Read from `arr[3]` and store in `$3`

Suppose `$1` is $40$. `arr[3]` would be at $52$ since $40 + (3 \times 4) = 52$

```asm
lis $4
.word 4
lis $3
.word 3
mult $3, $4
mflo $5 ; Has (4 x 3)
add $5, $1, $5
lw $3 0($5)
jr $31
```

Alternate implementation: `lw $1 12($5)`

## Testing Arrays

`mips.array program.mips`

## Procedures in Assembly

A **label** is associated with the address at that instruction by the assembler

**Procedure**: Label followed by instructions

**Issues**:

- Prevent procedure from overwriting other procedure's register values
- Calling and returning from a procedure

**Issue 1:**
- `$3` contains critical data
- Call procedure

```
proc:
    overwrite $3
    return
```

Value in `$3` is lost

**Solution 1**: Restricting procedures to a subset of registers

- Does not scale
- Disallows recursion

**Solution 2**: Use Memory (RAM)

- MIPS loader initializes `$30` to just past memory assigned to the program
- When a procedure is called, the procedure stores the previous register values in memory and updates `$30` bookmark
- Before returning, the new procedure restores the old register values. It updates `$30` again
- Using memory as a stack and treating `$30` as the stack pointer


```
_______________________________________
Code: MEM[0]

End of Code
_______________________________________
empty space



Procedures memory use this area

________________________________________
$30: End of allocated memory for program
________________________________________
Other program's memory
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
________________________________________
```

**Example:** `push $1`

- Take value in `$1` and push it to the top of the stack.

```asm
sw $1, -4($30)
lw $1
.word 4
sub $30, $30, $1
```

**Example:** `pop $5`

```asm
lw $5
.word 4
add $30, $30, $4
lw $5, -4($30)
```

**Issue 2:**

- How to return to address that called procedure?
- `beq` and `jr` will not work because no reference back
- Need to remember the program counter when calling a procedure

```asm
lis $8
.word proc
jr $8
```

This code can jump to `proc`, but how do you return back?

**Jump and Link Register:** `jalr $s`

- `$31 = PC, PC = $s`
- At the end of the procedure, `jr $31` takes you back to original location

Problem: This overwrites previous `$31`. How do you terminate program?

```asm
lis $8
.word proc
push $31
jalr $8
pop $31
jr $31 ; Returns properly :)
proc:
    do stuff
    jr $31
```

**Note:** Push and pop are not functions in MIPS. Must implement it with our implementation

**Convention:** Use registers unless a procedure requires $30$+ variables.

Procedures document argument expectations

#### Recursion

Works out of the box

**Example:**

```asm
sw $31 , -4($30)
lis $4
.word -4
add $30, $30, $4
lis $4
.word proc
jalr $4
lis 4
.word 4
add $40, $40, $4
lw $31, $-4(30)
...
jr $31
proc:
    ; Push registers that may be overwritten
    ; Procedure code
    ; pop registers (restores registers)
    jr $31
```

## Assembler

### Analysis

#### Input

- Scanning/tokenization (Reading and splitting input)
- Convert a sequence of characters into a sequence of tokens

```cpp
struct token  {
    Kind kind; //ID, REG, COMMA (enum)
    char * lexome; // Characters from input
    long long value; // constant
}

vector<Token> line;
```

##### Parsing

- Make sense of the sequence of tokens

```cpp
if (line[0].Kind = 11) &&
   (line[0].lexeme == "add") &&
   (line[1].Kind == REG) &&
   (line[2].Kind == COMMA) &&
   (line[3].Kind == REG) {
    ...
   } else {
    // syntax error
    // output ERROR to stderr
   }
```

- Check for valid syntax
    + Length of line
    + Range of registers
    + Range for branches (16 bit signed)

#### Labels in Assembly
- Branch (beq): `(offset = address of label - current PC)/4`
- `.word` label
- Assembler should keep track of virtual PC

**Symbol Table**: Store the address of each new label into a map

If we see `.word label`, lookup and output the address from the symbol table.

In `beq`, lookup label in table, and use the formula to calculate offset.

- There is no declaration before use for labels
- Assembler will need at least 2 passes.
    + Pass 1: Scanner and most syntax checking, creates symbol table
    + Pass 2: Remaining syntax checks, range checks, and generate output

Example:

```asm
main: lis $2
    .word 13
    lis $1
    .word -1
    add $3, $6, $0
loop:
begin: top: add  $3, $3, $2
    add $2, $2, $1
    bne $2, $0, top
end: jr $31
```

**Pass 1**: Generate Symbol Table

```
main -> 0
loop -> 20
top-> 20
begin ->20
end ->32
```

**Loader**: Read program from file on disk, and load it into ram.

#### OS 1.0

```
repeat:
    Choose program
    loader(p)
    jalr $0 // Assuming we load program at address 0
    beq $0, $0, repeat
```

#### Loader 1.0

```cpp
for (int i = 0; i < words; ++i) {
    MEM[4i] = file[i]
}
```

**Problem**: Cannot always assume that we can load the program at address 0

#### OS 2.0

```
repeat:
    p <- Choose program
    $3<-loader(p) // Starting address of where the program should be loaded
    jalr $3
    beq $0, $0, repeat
```

#### Loader 2.0

Assume `a` is the starting address of enough continuous memory to hold the program and associated stack.

```cpp
for (int i = 0; i < words; ++i) {
    MEM[a + 4i]= file[i]
}
```

**Problem**: Assembler assumes that the program is going to be loaded at address 0. Any line that contained a `.word <label>` is incorrect if the program does not start at address 0.

**Solution**: Add `a` to each line containing `.word <label>`. Assembler must provide information on locations of `.word <label>` to the loader.

Assembler will produce object code. (Machine code with additional information)

## MERL: MIPS Executable, Relocatable, Linkable

Assembler provides more information about the program:

- `beq $0, $0, 2`. This skips the next two lines and goes to the first line of the program
- End of file address
- End of code (Relocation entries)

`0x00000001` tells loader that the next line contains the address of a line that must be relocated

## Loader

Output MERL object code

- Header: 3 words
- Code
- Footer/table

#### Tools

`cs241.relasm` generates MERL output.

`cs241.merl` relocate a MERL file to a specific address and outputs a non-NON MERL file

`mips.twoints` and `mips.array` have an optional command line argument to provide starting address

```
java cs241.relasm < inputasm > out.merl
java cs241.merl 0x12345678 < out.merl > out.mips
java mips.twoints out.mips 0x12345678
```

#### MERL Output without `relasm`

- Add new labels for each occurrence of `.word label`
- Add label for end of code
- Add relocation entries
- Add label for end of module
- Add header:

```asm
beq $0, $0, 2
.word endmodule
.word endcode

.word A
.word B
endcode:
.word 1
.word reloc1
.word 1
.word reloc2
endofmodule:
```

#### Loader 3.0

```
________________
memory
_______________
start of program
beq $0, $0, 2
addr endmodule
addr endcode
---------------
code
endcode:
---------------
footer
endmodule:
---------------
```

Need the address if the symbol table. This is at `MEM[a+8]`.

The actual address is `MEM[a+8] + a`

```cpp
start <- MEM[a+8] + a
end <- MEM[a+4] + a
while (start < end) {
    if (MEM[start == 1])
        MEM[MEM[start + 4] + a] += a
        start += 8
    }
}
```

## Linkers

**Problem**: How to resolve labels that are defined in a different file?

**Solution 1**: Concatenate all files and run assembler on concatenated files

**Limitation**:

- Need to assemble entire project every time.
- Inefficient
- How to deal with relocations? Only one file can be loaded at address 0
- Concatenating MERL files produces two tables

**Solution 2**: Use a tool that understands how to combine MERL files

**Limitation**: Since we will assemble first and then link, the assembler has to tell the linker of any unresolved labels.

- Assembler will output (in the MERL footer) an entry to indicate that an external symbol reference is still unresolved
- We do not want the assembler to add an ESR (External Symbol Reference) entry for every label that's not found.
- To use an external symbol, programmer must import

```asm
.import <label> ; Allows reference <label> externally
```

If assembler sees `.word proc` but no `.import proc`, the assembler will generate an error

```asm
.word 0x11 ; next addr is an ESR (External Symbol Reference)
.word <addr> ; address where word is imported
.word <length of label>
.word <ascii value 1 of label>
...
.word <ascii value of nth letter in label>
```

If we want labels to be visible to other files, we must use `.export <label>`

For each exported label, an External Symbol Definition (ESD) is created.


```asm
.word 0x05 ; next addr is an ESD (External Symbol Definition)
.word <addr> ; address where word is defined
.word <length of label>
.word <ascii value 1 of label>
...
.word <ascii value of nth letter in label>
```

When linking the files together, it will look like

```
header
file1 code
file2 code
```

`file2` code will be offset by `m1code - file2.header`

- Match all ESR from `file1` with ESD from `file2`
- Once matched, update the value of the `.word <label>` using the address from the ESD and remove the ESR.
- Replace the ESR with the relocation entry

## Formal Languages

An implementation (assembler/compiler) is useful to check what is allowed/not allowed in a language.

**Limitation**: Who guarantees that the implementation is correct?

A **formal language** is a mathematically precise way of saying what is/isn't allowed by a language.

**Noam Chomsky** used mathematics (set theory) to create a hierarchy of languages called the Chomsky Hierarchy.

**Definitions**:

**Alphabet**: (denoted $\sum$) a finite set of symbols. (Example: $\{0,1\}$ is the binary alphabet)

Symbols can be multiple characters. Example $\sum = \{jr,add,\$1\}$

**Word**: An ordered finite sequence of symbols (Example `jr $31` is a word in the MIPS alphabet)

There is a word $\epsilon$, the word with 0 symbols.

Language: A possibly infinite set of words.

Example: $\sum = \{0,1\}$ and $L =$ `{ all binary numbers of length 8}`. Therefore $|L| = 2^8$

The empty language, denoted $\epsilon$ is the language with 0 words.

**Specification:** Precisely define what is/isn't valid

**Recognition:** A decision algorithm that takes a specification of an input word and answers whether the word is in the language.

Note that there are languages which do not have a recognition algorithm.

**Interpretation/Translation**: Converting input to a desired output.

Assembler/Compiler must do both recognition (analysis) and translation (synthesis)

How hard is it to do recognition? It depends

Classify languages based on how difficult their recognition algorithm is. (Easy to hard)

- Finite Languages
- Regular Languages
- Context Free Languages
- Context Sensitive Languages
- Recursive Language
- Undecidable Language

## Finite Languages

Language which has a finite set of words.

**Specification**: List all the words in the language.

**Recognition**: Check if a given word is in the set of words that define that language

**Example**: $L = \{cat, co, car\}$ To check if $w \in L$, start with checking whether first letter is $c$. If not, can immediately terminate and say no. Trie seems to work really well here

Move through transitions, changing state every time. A state is something like "start", "seen c", "seen ca", "seen cat", etc.

**Example**:  $L =$ {all MIPS keywords}

## Regular Languages

**Building Blocks**:

- Finite languages
- Union
- Concatenation
- Repetition

Union: $L_1 \cup L_2 = \{x: \,x \in L_1 , x \in L_2\}$

**Concatenation**: $L_1 L_2 = \{xy: x \in L_1, y \in L_2\}$

$L_1 = \{dog, cat\}, L_2 = \{fish, \epsilon\}$

$L_1 L_2 = \{ dogfish, dog, catfish, cat\}$

**Repetition**: $L^* = \{ \epsilon\} \cup \{xy: x \in L^*, y \in L \}$

A regular language can be specified using a DFA, NFA, $\epsilon$-NFA, or RE.

## Deterministic Finite Automaton

Regular languages (DFA) are used in writing scanners.

Formal Definition: A DFA is a 5-tuple $(\sum, Q, q_0, A, \delta)$

- $\sum$: Alphabet
- $Q$: Set of states
- $q_0$: Starting state
- $A$: Set of accept states
- $\delta$: $f: (x \in Q, y \in \sum) \rightarrow z \in Q$. Applies transition to a state

## Recognition

Input $w = a_1a_2 \dots a_n, a_i \in \sum$

$L(DFA) \rightarrow$ yes/no is $w \in L(DFA)$

```
state = q
for i in 1 to n:
    state = sigma(state, a_i)
end for

return (state in A)
```

**Note:** A word is accepted by the DFA if the recognition algorithm returns true, the given the word leads the DFA into an accept state.

The language specified by a DFA is the set of all words accepted by the DFA.

A language is regular if there exists a DFA for it.

**Example:** Words with the same number of a's and b's in any order (this is not a regular language because states will be infinite)

## DFA with actions/ Finite Transducers

$$\sum = \{0,1\}$$

$L = \{$ a binary number with no leading zeros $\}$

In a finite transducer, we can associate an action with a transition.

Assume $n$ is a global variable.

At a branch in the DFA, modify the global variable.

#### DFA Accepting all BIN/DEC/HEX

```
(0) -> 0 -> (0)
(0) -> 1-9 -> () -> loop 0-9
(0) -> 0 () -> x -> () -> 0-9/A-F -> (()) -> loop -> 0-9/A-F
```

This is not a DFA because the expression is ambiguous and is not deterministic. This is a Non deterministic finite automaton.

NFAs can also be used to represent regular languages. A word is accepted by an NFA if a path stops at an accept state.

## Non Deterministic Finite Automaton

- $\sum$: Alphabet
- $Q$: Set of states
- $q_0$: Starting state
- $A$: Set of accept states
- $\delta: (Q \times \sum) \rightarrow P(Q)$ where $P(Q)$ is the power set of $Q$. (all possible subsets of $Q$)


$L(NFA) = \sum, Q, q_0, A, \delta$

Yes/no, is $w \in L(NFA)$

```
states = {q_0}
for i in 1 to n:
    states = \Union_{s_j \in states} sigma(s_j, a_i)
end for
return states intersect A > 0
```

**Note:** DFAs are easier to implement while NFAs are easier to create.

Epsilon NFAs have an epsilon as the first transition to multiple states. The transition does not consume any symbol.

**Example**:

$$ \sum = \{a,b,c\}, L_1 = \{cab\}, L_2 = \{\text{ even number of a's}\}$$

```
() -> c -> () -> a -> () -> b (())
() -> (()) -> loop -> <- b,c -> a -> () -> loop -> bc
```

To merge the two NFAs, we can use epsilon NFA, and use epsilon as the starting transition for both NFAs.

```
() -> epsilon -> () -> c -> () -> a -> () -> b (())
() -> epsilon  -> () -> (()) -> loop -> aa -> a -> () -> loop -> bc
```

Epsilon closure of a state S is the set of all possible states that are reachable from the states in S using 0 or more epsilon transitions.

Input $w = a_1a_2 \cdots a_n, a_i \in \sum$

```
states = epsilon_closure(q_0)

for i in 1 to n:
    state = epsilon_closure(\Union_{j \in states}) \sigma(s_j, a_ijj)
end for
return states intersect A > 0
```

## Regular Expression

- $epsilon$: Empty word
- $a, a \in \sum$: The word matched by $a$ is in the alphabet
- $R_1 R_2$: A word matched by $R_1$ followed by a word matched by $R_2$ (Concatenation)
- $R_1 | R_2$: Either word $R_1$ or the word $R_2$ (Union)
- $R^*$: 0 or more occurrences of words matched by $R$

**Convention:** $a|bc^* \equiv a | (b(c^*))$

**Example:** $L = \{cab, car, card \}$

**Regular Expression**: $cab \,|\, car \,|\, card$ or $ca(b|r(\epsilon|d))$

**Example:** $\sum = \{a,b\}$, $L = \{ \text{all strings containing aa}\}$

$(a|b)^*aa(a|b)^*$ is an ambiguous regex for this.

**Kleene's Theorem:** A language is regular if

- there exists a regular expression for it
- there exists an $\epsilon$ NFA for it
- there exists an NFA for it
- there exists a DFA for it.

$$RE \iff \epsilon-NFA \iff NFA \iff DFA$$

**Proof**:

$$RE \implies \epsilon-NFA$$

- $\emptyset$ is just the start state
- $\epsilon$ is the valid start state
- $a$ is a transition with $a$
- $R_1|R_2$ can be achieved by using an epsilon transition to connect to start state of $R_1$ and $R_2$
- $R_1R_2$ is connecting each finish state in $R_1$ to start state in $R_2$. $R_1$'s finish state will not be valid states anymore
- $R^*$ is creating a new state as start and accepting state, connect it to start state with epsilon, and loop back to start state for every valid end state (with epsilon transition).

$$\epsilon-NFA \implies NFA$$

- For every chain of $\epsilon$ transitions followed by a transition on a symbol $a$, add the transition $a$ from the beginning of the chain to the state $a$ transitions to.
- If the target state of an $\epsilon$ transition is an accept state, make the source state also an accepting state.
- Remove all $\epsilon$ transitions and any unreachable states.

$$NFA \implies DFA$$

This is called subset construction.

- An NFA can transition to multiple states. Construct a state that is a subset of all possible states given a particular transition. Then there on each transition, we can only be in one state at a time.
- Any accepting state in the original NFA that is a subset of a state will have the new state as an accepting state.

## Recognition in Scanning

- Input DFA, NFA
- Input: $w=a_1,\cdots a_n, a_i \in \sum$
- Output: yes/no is $w \in L$

### Scanning

Converting a sequence of characters into a sequence of tokens. (Often referred to as tokenization)

- Input: String $s$
- Input: DFA
- Output: $w_1w_2 \cdots w_n = s$

$L = \{ \text{tokens for programming language}\}$

Suppose this language is regular.

$M_L =$ DFA for recognizing a single word from $L$.

Machine can recognize any amount of words by adding an $\epsilon$ transition from every accept state to the start state. This accepts $LL^*$

During $\epsilon$ transition, output the token (as an action) and we can generate a sequence of tokens.

#### Problem

$L = \{aaa, aa\}$

This isn't deterministic. $aaaaa$ can be formed with $\{aaa, aa\}$ or $\{aa, aaa\}$

$s = aaaa$

Either $\{aa, aa\}$ valid, or $\{aaa\}$ and then the input is invalid.

## Maximal Munch Algorithm

- Greedy algorithm
- Always deterministic
- Might sometimes not give tokenization (even if one exists)

Always takes the maximum token length at every transition.

- Input: $aaaaa$, Output: $\{aaa, aa\}$
- Input: $aaaa$, Output: $\{aaa\}$ and then the input is invalid.

#### Algorithm

- Start with the DFA that recognizes a single word
- Run input program through this DFA
- Acceptance:
    + If at accepting state, good
    + Otherwise backtrack to last seen accepting state
    + If no such state exists, output error

- Output a token
- reset current state to start state

**Example:**

```java
int i = 1
int j = 1
println(i+++j) // i++ + j
println(i+++++j) // i++ ++ + j is invalid
println(i+++ ++j) // i++ + j++ is valid
```

```cpp
vector<vector<int >> // the >> gets interpreted as bit shift and cannot compile in C++03
vector<vector<int > > //  Solution: Put space
```

```cpp
y/*z  // This will not compile as /* is the beginning of a comment */
y/ *z // Solution is to put a space
```

#### Semantics

- Input: string $s$
- Input: L(DFA)
- Output: $s = w_1,w_2,\cdots, w_n, w_i \in L(DFA)$ and $w_i$ is the longest prefix from $w_i, w_{i+1}, \cdots w_n$

**Worst case scenario**:

$L = abc|(abc)^*d$

Input: $abcabcabcabcabcabc$

Correct separation: $\{abc, abc, abc, abc, abc, abc\}$

However, maximal munch will match $(abc)^*d$ until the very end, and then backtrack.

Worst case: $O(n^2)$

## Simplified Maximal Munch

When stuck at an non-accepting state, just output error.

WLP4 tokens from the same class must be separated by whitespace

```python
i = 0
state = q_0
loop
    if (\delta(state, s_i) is defined):
        state = \delta(state, s_i)
        i++
    else:
        if (state is not Accepting):
            error quit
        output token
        state = q_0
        if EOF:
            quit
end loop
```

## Parsing

Parts of a compiler

Input -> Scanner -> Sequence of tokens (Lexically correct) -> Parser -> Parse tree (Syntax correct) -> Semantic analysis/ Context sensitive analysis

-> parse tree + symbol table + types, etc -> semantically valid -> Code generator -> MIPS assembly

**Parsing:** Figuring out structure of the program.

**Example:**  Structured Mathematical Operations. Will need infinite number of states in DFA to represent an arbitrary number of balanced parenthesis. (Using a regular language)

**Context Free Languages:**

- Specified using content free grammar
- expr -> id
- expr -> expr op expr
- id -> a|b|c
- op -> +|-|\*|/

Context Free Grammar is a set of rewrite rules. Replaces repetition with recursion

Start with the start symbol (expr), and replace it with the corresponding RHS of a rule

$a + b$

- expr $\implies$ expr op expr
- $\implies$ id op expr
- $\implies$ id + expr
- $\implies$ id + id
- $\implies$ a + id
- $\implies$ a + b

#### Adding Parentheses

Add new rule:

expr $\implies$ ( expr )

**Example:**

- expr $\implies$ ( expr )
- $\implies$ ((expr op expr))
- $\implies$ (((expr) op expr))
- $\implies$ (((expr op expr) op expr))

#### Goal

- Specify programming language syntax using CFG.
- Start at start symbol of CFG and try to derive the input (output of the scanner)
- If we cannot find one, parsing error
- Valid -> create parse tree

Formally, a Context Free Gramar is a 4 tuple

- N: Finite set of non terminals
- T finite set of terminals
- S: Unique start symbol ($S \in N$)
- P: Finite set of production rules
- V: $N \cup T$

$P \subseteq N \times V^*$

$A \to \alpha$ where $A \in N$ and $\alpha$ is a sequence of terminals and non-terminals

- Non terminal can appear on the LHS or RHS of a rule
- Terminal can only appear on the RHS
- There must be at least one rule for each non-terminal

#### Conventions

- $a,b,c,d \in T$ (single terminal)
- $A,B,C,S \in N$ (single non-terminal)
- $W,X,Y,Z \in V = N \cup T$ (single symbol)
- $w,x,y,z \in T^*$ (string of terminals)
- $\alpha, \beta, \gamma \in V^*$ (string of terminals/non-terminals)

#### Definitions

**Directly Derive**: A single application of a rule

$\alpha A \gamma \implies \alpha \beta \gamma$ if $A \implies \beta$ is a rule.

**Derive**: we say $X_1 \implies^*X_n$ if $X_1 \implies X_2 \implies \cdots \implies X_{n-1} \implies X_n$

$\alpha \implies^* \beta$ if $\alpha = \beta$ or $\alpha \implies \gamma$ and $\gamma \implies^* \beta$

**Derivation**: A sequence $\alpha_0, \alpha_1,\cdots,\alpha_n$ such that

- $a_0$ is the start symbol
- $a_n$ is a string of just terminals
- $\alpha_i \implies \alpha_{i+1}$

Show $expr \implies^* a + b - c$

- expr $\implies$ expr op expr
- $\implies$ expr op expr op expr
- $\implies$ id op expr op expr
- $\implies$ a op expr op expr
- $\implies$ a + expr op expr
- $\implies$ a + id op expr
- $\implies$ a + b op expr
- $\implies$ a + b - expr
- $\implies$ a + b - id
- $\implies$ a + b - c

**Definition**: The language defined by the CFG G is the set of strings of terminals that can be derived starting at the start symbol $S$.

$$L(G) = \{x \in T^* | S \implies^* x\}$$

The language is context free if it can e specified using a CFG.

It is undecidable whether two CFGs specify the same language

**Recognition**: yes/no is $s \in L(G)$

**Parsing**: Prove that $s \in L(G)$ by providing a derivation

**Example**:

- $N = \{A,B,C\}$
- $T = \{a,b,c,d,e,f,g,h\}
- $S = A$ (Start symbol)
- $A \implies BgC$
- $B \implies ab$
- $B \implies cd$
- $C \implies h$
- $C \implies ef$

$L = \{abgh, cdgb, abgef, cdgef\}$

Parse $abgef$

- $A \implies BgC \implies abgC \implies abgef$
- $A \implies BgC \implies Bgef \implies abgef$

We have two derivations for the same string

#### Parse Tree

- Root - start symbol
- Leaf Nodes: Terminals
- Node $A$ can have children $WXY$ if $A \implies WXY \in P$

**Properties**:

1. A derivation uniquely defines a parse tree

    - expr $\implies$ expr op expr
    - op $\implies$ +|-|\*|/
    - expr $\implies$ id
    - $T = \{+, -, *, /\}$

    Input string: id - id * id

    - exp $\implies$ expr op expr
    - $\implies$ expr op expr op expr
    - $\implies$ id op expr op expr
    - $\implies$ id - expr op expr
    - $\implies$ id - id op expr
    - $\implies$ id - id * expr
    - $\implies$ id - id * id

2. A parse tree can have multiple derivations (but derivation uniquely defines parse tree)

    - exp $\implies$ expr op expr
    - $\implies$ expr * expr
    - $\implies$ expr * id
    - $\implies$ expr op expr * id
    - $\implies$ id op expr * id
    - $\implies$ id - expr * id
    - $\implies$ id - id * id

3. An input string can have multiple derivations (similar to parse tree example).

    - Order of operations doesn't exist. Therefore multiple derivations exist.

## Leftmost Derivation (Left Canonical Derivation)

- Always expand the leftmost non-terminal.
- $\underbrace{xA\gamma}_{\alpha i} \implies \underbrace{x\beta \gamma}_{a_{i+1}}$
- for $A \implies \beta$

#### Rightmost Derivation

- Always expand rightmost non-terminal.
- $\gamma Ax \implies \gamma \beta x$
- for $A \implies \beta$

**Property**: From a given derivation style, a parse tree has a unique derivation.

**Problem**: The two derivations previously for $id - id * id$ are both leftmost derivations.

**Ambiguous Grammar**: A grammar is ambiguous if there exists a string in the language for which there exist multiple parse trees, even when using a fixed derivation style.

#### Unambiguous Grammar

No proof to show unambiguity. Undecideable problem

- expr -> expr op term | term
- term -> id | (expr)
- op -> +|-|\*|/

**Note**: Parenthesis added just to show order of operations and evaluation in parse tree

- expr \$implies$ expr op term
- $\implies$ (expr op term) op term
- $\implies$ (id op term) op term
- $\implies$ (id - term) op term
- $\implies$ (id - id) op term
- $\implies$ (id - id) * term
- $\implies$ (id - id) * id

What if we want order of operations? We want multiplication and division to be deeper than addition and subtraction in the parse tree.

Give * and / precedence over + and -.

- asdf -> expr pm term | term
- pm -> +|-
- term -> term md factor | factor
- md -> \*|/
- factor -> id | (expr)

**Note**: Parenthesis added just to show order of operations and evaluation in parse tree

- expr $\implies$ expr pm term
- $\implies$  (term) pm term
- $\implies$  factor pm term
- $\implies$  id pm term
- $\implies$  id pm (term md factor)
- $\implies$  id pm (factor md factor)
- $\implies$  id pm (id md factor)
- $\implies$  id pm (id * factor)
- $\implies$  id pm (id * id)

**Example:**

```cpp
int x = 0;
int y = 8;
if (x < 5)
    if (y > 10)
        print "A"
    else
        print "B";
```

A warning will appear "dangling else". Without putting braces, the expression is ambiguous. Unknown whether else belongs to first or second if statement. Note that the compiler doesn't look at whitespace and indentation.

# ---------------- Midterm Stops Here ----------------------

## Parsing

- Input: Unambiguous grammar and tokens
- Action: Parse in $O(n)$
- Output: Derivation

**Top down parsing**: Start with root symbol and work down

**Bottom up parsing**: Start with derivation and build upwards

Parsing algorithms "like" having only one rule for the start symbol

**Augmenting a Grammar**:

$G' = \{N \cup \{S'\}, T \cup \{\vdash, \dashv\}, S', P \cup \{S' \implies \vdash S \dashv \}\}$

$S'$ is the start symbol

where $\vdash$ is BOF and $\dashv$ is EOF

**Algorithm**:

- When we see terminals, match with input
- Find a rule for the first leftmost non-terminal ($A \rightarrow B$)
- Replace LHS of rule with RHS

# Refer to example posted online

